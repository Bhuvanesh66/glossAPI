{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39e34c75-cdaf-4aaf-91cc-f6a932129162",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch import nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05192a61-0247-4636-9e03-b2f5e6261cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class BertForMultivariateRegression(nn.Module):\n",
    "    def __init__(self, model_name_or_path, num_labels=5):\n",
    "        super(BertForMultivariateRegression, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "        self.bert = AutoModel.from_pretrained(model_name_or_path, config=self.config)\n",
    "        self.regression = nn.Sequential(\n",
    "            nn.Linear(self.bert.config.hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, num_labels),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Dropout(0.1),\n",
    "            #nn.Linear(128, ),\n",
    "        )\n",
    "        self.init_weights()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(self.device)\n",
    "\n",
    "    def init_weights(self):\n",
    "        for module in self.regression:\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        pooler_output = outputs.pooler_output\n",
    "        logits = self.regression(pooler_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.MSELoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "\n",
    "        return (loss, logits) if loss is not None else logits\n",
    "\n",
    "    def save_pretrained(self, save_directory):\n",
    "        os.makedirs(save_directory, exist_ok=True)\n",
    "        self.config.save_pretrained(save_directory)\n",
    "        torch.save(self.state_dict(), os.path.join(save_directory, \"pytorch_model.bin\"))\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, save_directory, model_name_or_path, num_labels=5):\n",
    "        config = AutoConfig.from_pretrained(save_directory)\n",
    "        model = cls(model_name_or_path, num_labels=num_labels)\n",
    "        state_dict = torch.load(os.path.join(save_directory, \"pytorch_model.bin\"), map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(state_dict)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7552aa22-6752-4775-9525-5567f9026760",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7557a3bda0b343e08058f303fa9aac2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4baf70dcd742f3950868725997f57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/454M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertForMultivariateRegression(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (regression): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the model\n",
    "model = BertForMultivariateRegression.from_pretrained(\"./saved_model\", model_name_or_path=\"nlpaueb/bert-base-greek-uncased-v1\", num_labels=5)\n",
    "model = model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad1c41f8-31c4-46a4-94c7-612d5162bc3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd70f872627e4e47835e6915da41482a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4310257225945ef8ad234a5643e4393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/530k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ed6c4915274ed1abeb84ac8a5a7de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\")\n",
    "\n",
    "# Load the prediction data\n",
    "prediction_data = pd.read_csv(\"cleaned_draw2texts.csv\", sep=\",\", engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea490ad2-e6b2-4a98-9161-a587c372cc9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67b962f7-646d-4b26-beed-213b13677976",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Και πριν αυτος παυση λαλων , ιδου , εξηρχετο η...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Και την τριτην ημεραν , ημεραν των γενεθλιων τ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Οι οφθαλμοι σας ειδον τι εκαμεν ο Κυριος εξ αι...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Και εβοησεν ο Αχιμαας και ειπε προς τον βασιλε...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Και ηλθε Σαφαν ο γραμματευς προς τον βασιλεα κ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Με την πρόταση αυτή η Επιτροπή επιχειρεί να πρ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Αυτές οι προτάσεις για μεγαλύτερη διαφάνεια στ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Κυρία Πρόεδρε , κύριε Πρόεδρε του Συμβουλίου M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Αυτό αποτελεί μια σημαντική ευκαιρία να τεθούν...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Μια ακόμα κρίσιμης σημασίας παράμετρος είναι ,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    Και πριν αυτος παυση λαλων , ιδου , εξηρχετο η...\n",
       "1    Και την τριτην ημεραν , ημεραν των γενεθλιων τ...\n",
       "2    Οι οφθαλμοι σας ειδον τι εκαμεν ο Κυριος εξ αι...\n",
       "3    Και εβοησεν ο Αχιμαας και ειπε προς τον βασιλε...\n",
       "4    Και ηλθε Σαφαν ο γραμματευς προς τον βασιλεα κ...\n",
       "..                                                 ...\n",
       "114  Με την πρόταση αυτή η Επιτροπή επιχειρεί να πρ...\n",
       "115  Αυτές οι προτάσεις για μεγαλύτερη διαφάνεια στ...\n",
       "116  Κυρία Πρόεδρε , κύριε Πρόεδρε του Συμβουλίου M...\n",
       "117  Αυτό αποτελεί μια σημαντική ευκαιρία να τεθούν...\n",
       "118  Μια ακόμα κρίσιμης σημασίας παράμετρος είναι ,...\n",
       "\n",
       "[119 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45ee729f-b2e2-45a7-81fc-23af4a969d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the scaling parameters\n",
    "#with open(\"scaling_params.json\", \"r\") as f:\n",
    "#    scaling_params = json.load(f)\n",
    "\n",
    "# Function to check if text exceeds token limit\n",
    "def exceeds_token_limit(text, max_length=512):\n",
    "    return len(tokenizer.encode(text)) > max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e8d31b9-5fd1-4c4c-aa03-66bdbb9f5f09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter out texts exceeding token limit\n",
    "valid_mask = prediction_data['text'].apply(lambda x: not exceeds_token_limit(x))\n",
    "filtered_data = prediction_data[valid_mask]\n",
    "\n",
    "# Tokenize the valid input texts\n",
    "inputs = tokenizer(filtered_data['text'].tolist(), padding=True, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8461102d-640f-452b-9166-241b60f6b4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbecf086-ec07-41b0-ae58-3e38e2e31662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    predictions = model(**inputs)\n",
    "    predictions = predictions.cpu().numpy()\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "predicted_data = pd.DataFrame(predictions, columns=['1', '2', '3', '4', '5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d676008-6a77-4d0d-8bfa-10189512ca80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaling_params = {'min_vals': [0.9014031435288774,\n",
    "  -0.20944372492040664,\n",
    "  0.3389173248677211,\n",
    "  0.5175195569772773,\n",
    "  0.9111702659370386],\n",
    " 'scale': [0.09026005554938518,\n",
    "  0.11147839708128467,\n",
    "  0.05688428995404781,\n",
    "  0.0417984150486127,\n",
    "  0.014517997301216296],\n",
    " 'data_min': [-21.0658317453454,\n",
    "  -7.0915647854459,\n",
    "  -23.5375588927861,\n",
    "  -36.3056722416953,\n",
    "  -131.641453451498],\n",
    " 'data_max': [1.09236423433371,\n",
    "  10.8491309220973,\n",
    "  11.6215333911404,\n",
    "  11.5430320135724,\n",
    "  6.11859419863091]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b5bbc7e-312c-48c4-9e13-aec9c30c4a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale the predictions to their original ranges\n",
    "for i in range(5):\n",
    "    scaler = MinMaxScaler(feature_range=(scaling_params['data_min'][i], scaling_params['data_max'][i]))\n",
    "    predicted_data[[str(i+1)]] = scaler.fit_transform(predicted_data[[str(i+1)]])\n",
    "\n",
    "# Add the original text to the predictions\n",
    "predicted_data['text'] = filtered_data['text'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fadf5cc-e28a-4a09-8133-ba2c96d44819",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame for all original data, with NaN for removed texts\n",
    "full_predicted_data = pd.DataFrame(index=prediction_data.index, columns=['text', '1', '2', '3', '4', '5'])\n",
    "full_predicted_data.loc[valid_mask, ['1', '2', '3', '4', '5']] = predicted_data[['1', '2', '3', '4', '5']]\n",
    "full_predicted_data['text'] = prediction_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7a630a2-b524-4ec9-9383-5c5f59e23812",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text          1         2  \\\n",
      "0  Και πριν αυτος παυση λαλων , ιδου , εξηρχετο η... -16.040192  0.746675   \n",
      "1  Και την τριτην ημεραν , ημεραν των γενεθλιων τ... -10.927856 -0.993885   \n",
      "2  Οι οφθαλμοι σας ειδον τι εκαμεν ο Κυριος εξ αι... -11.083191 -0.825089   \n",
      "3  Και εβοησεν ο Αχιμαας και ειπε προς τον βασιλε... -13.251968 -0.657799   \n",
      "4  Και ηλθε Σαφαν ο γραμματευς προς τον βασιλεα κ... -10.781921  -0.68861   \n",
      "5  Τοτε εσηκωθησαν οι αρχηγοι των πατριων του Ιου... -10.287888 -1.609157   \n",
      "6  Η Εσθηρ δεν εφανερωσε την συγγενειαν αυτης ουτ... -11.145554 -1.151065   \n",
      "7  Και ευρον οτι πικροτερα ειναι παρα θανατον η γ... -13.259445  2.831925   \n",
      "8  Και ουτω θελει προσμεινει ο Κυριος δια να σας ... -15.395737  0.030364   \n",
      "9  Και θελω συντριψει αυτους μετ αλληλων , και το... -11.052994  0.568834   \n",
      "\n",
      "          3          4          5  \n",
      "0  8.190218  -9.984833 -26.493286  \n",
      "1   5.70701  -8.580276 -30.511108  \n",
      "2  4.103956 -13.183258 -22.870483  \n",
      "3  4.665052  -9.652122 -27.539917  \n",
      "4  3.876482 -10.166985 -31.968628  \n",
      "5  3.777998  -9.114693  -36.64209  \n",
      "6  4.261786  -9.595718 -36.476685  \n",
      "7  6.204679 -20.141296 -27.188477  \n",
      "8  4.805975 -10.201401  -22.29248  \n",
      "9 -1.596189 -20.677376 -22.075806  \n",
      "\n",
      "Number of texts removed due to exceeding token limit: 0\n",
      "\n",
      "Predictions saved to 'cleaned_draw2text_predicted.csv'\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the predictions, including removed texts\n",
    "print(full_predicted_data.head(10))\n",
    "\n",
    "# Print the number of removed texts\n",
    "num_removed = (~valid_mask).sum()\n",
    "print(f\"\\nNumber of texts removed due to exceeding token limit: {num_removed}\")\n",
    "\n",
    "# Save the results to a CSV file\n",
    "full_predicted_data.to_csv(\"cleaned_draw2text_predicted.csv\", index=False)\n",
    "print(\"\\nPredictions saved to 'cleaned_draw2text_predicted.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "161ec35e-b869-49a5-905f-1ebec4f47e1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts removed due to exceeding token limit: 0\n"
     ]
    }
   ],
   "source": [
    "num_removed = (~valid_mask).sum()\n",
    "print(f\"Number of texts removed due to exceeding token limit: {num_removed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3ac4a6e-1d23-4918-9ec0-d78904f687a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [text]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "removed_texts = prediction_data[~valid_mask]\n",
    "print(removed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70e57cd5-a90d-4384-9d30-846d2553da5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts exceeding token limit:\n",
      "Empty DataFrame\n",
      "Columns: [text]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "token_lengths = prediction_data['text'].apply(lambda x: len(tokenizer.encode(x)))\n",
    "print(\"Texts exceeding token limit:\")\n",
    "print(prediction_data[token_lengths > 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f46225b-b602-4783-bb39-60ca710e97a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text         1         2  \\\n",
      "114  Με την πρόταση αυτή η Επιτροπή επιχειρεί να πρ... -3.500702 -6.479919   \n",
      "115  Αυτές οι προτάσεις για μεγαλύτερη διαφάνεια στ... -3.174026 -5.971175   \n",
      "116  Κυρία Πρόεδρε , κύριε Πρόεδρε του Συμβουλίου M... -7.844177 -3.853869   \n",
      "117  Αυτό αποτελεί μια σημαντική ευκαιρία να τεθούν... -1.122894    -5.959   \n",
      "118  Μια ακόμα κρίσιμης σημασίας παράμετρος είναι ,...  0.580551 -5.980046   \n",
      "\n",
      "             3          4          5  \n",
      "114 -17.953266  -8.618385 -55.333374  \n",
      "115   -15.6772 -11.498337 -49.696289  \n",
      "116  -8.865986 -11.874023 -73.174744  \n",
      "117 -16.702127 -12.272057 -73.485474  \n",
      "118 -15.609471  -9.517403 -43.477783  \n"
     ]
    }
   ],
   "source": [
    "print(full_predicted_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68cfe405-570b-4975-b7fd-bf3edc42fd7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of filtered_data: (119, 1)\n",
      "Shape of predictions: (119, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of filtered_data:\", filtered_data.shape)\n",
    "print(\"Shape of predictions:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71c19efe-5d36-44b7-804f-0a23db937747",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of valid_mask: 119\n",
      "Number of rows in filtered_data: 119\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum of valid_mask:\", valid_mask.sum())\n",
    "print(\"Number of rows in filtered_data:\", len(filtered_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14292bcb-708d-4c6b-8908-b1e3d52d6bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of prediction_data: (120, 2)\n",
      "Shape of filtered_data: (119, 2)\n",
      "Shape of predictions: (119, 5)\n",
      "Shape of predicted_data: (119, 6)\n",
      "Shape of full_predicted_data: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of prediction_data:\", prediction_data.shape)\n",
    "print(\"Shape of filtered_data:\", filtered_data.shape)\n",
    "print(\"Shape of predictions:\", predictions.shape)\n",
    "print(\"Shape of predicted_data:\", predicted_data.shape)\n",
    "print(\"Shape of full_predicted_data:\", full_predicted_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0302e9-172e-4282-8778-7cbf50114856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
